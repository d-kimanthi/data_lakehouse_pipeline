{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f2c8088",
   "metadata": {},
   "source": [
    "# E-Commerce Streaming Analytics - Local Development\n",
    "\n",
    "This notebook provides tools for local development and testing of the streaming analytics pipeline.\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "Make sure all local services are running:\n",
    "- Kafka (localhost:9092)\n",
    "- MinIO (localhost:9000)\n",
    "- Spark (localhost:8081)\n",
    "- PostgreSQL (localhost:5432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dc1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e172754",
   "metadata": {},
   "source": [
    "## Test Kafka Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82cfd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Kafka connection\n",
    "def test_kafka_connection():\n",
    "    try:\n",
    "        producer = KafkaProducer(\n",
    "            bootstrap_servers=['localhost:9092'],\n",
    "            value_serializer=lambda x: json.dumps(x).encode('utf-8')\n",
    "        )\n",
    "        \n",
    "        # Send test message\n",
    "        test_message = {\n",
    "            'event_type': 'test',\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'message': 'Hello from Jupyter!'\n",
    "        }\n",
    "        \n",
    "        producer.send('raw-events', value=test_message)\n",
    "        producer.flush()\n",
    "        producer.close()\n",
    "        \n",
    "        print(\"âœ… Kafka connection successful!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Kafka connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "test_kafka_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9760bd94",
   "metadata": {},
   "source": [
    "## Test MinIO (S3) Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2838d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MinIO connection\n",
    "def test_minio_connection():\n",
    "    try:\n",
    "        s3_client = boto3.client(\n",
    "            's3',\n",
    "            endpoint_url='http://localhost:9000',\n",
    "            aws_access_key_id='minioadmin',\n",
    "            aws_secret_access_key='minioadmin',\n",
    "            config=Config(signature_version='s3v4'),\n",
    "            region_name='us-east-1'\n",
    "        )\n",
    "        \n",
    "        # List buckets\n",
    "        response = s3_client.list_buckets()\n",
    "        buckets = [bucket['Name'] for bucket in response['Buckets']]\n",
    "        \n",
    "        print(\"âœ… MinIO connection successful!\")\n",
    "        print(f\"Available buckets: {buckets}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ MinIO connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "test_minio_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0d24b5",
   "metadata": {},
   "source": [
    "## Test Spark Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421409c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Spark connection\n",
    "def test_spark_connection():\n",
    "    try:\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"LocalTest\") \\\n",
    "            .master(\"spark://localhost:7077\") \\\n",
    "            .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "            .getOrCreate()\n",
    "        \n",
    "        # Create test DataFrame\n",
    "        test_data = [(1, \"test\", datetime.now())]\n",
    "        columns = [\"id\", \"message\", \"timestamp\"]\n",
    "        df = spark.createDataFrame(test_data, columns)\n",
    "        \n",
    "        print(\"âœ… Spark connection successful!\")\n",
    "        print(f\"Spark version: {spark.version}\")\n",
    "        df.show()\n",
    "        \n",
    "        spark.stop()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Spark connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "test_spark_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891c6fcc",
   "metadata": {},
   "source": [
    "## Generate Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59761e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample e-commerce events\n",
    "def generate_sample_events(num_events=10):\n",
    "    events = []\n",
    "    event_types = ['page_view', 'add_to_cart', 'purchase', 'user_signup']\n",
    "    \n",
    "    for i in range(num_events):\n",
    "        event = {\n",
    "            'event_id': f'evt_{i:06d}',\n",
    "            'event_type': random.choice(event_types),\n",
    "            'user_id': f'user_{random.randint(1, 1000):04d}',\n",
    "            'product_id': f'prod_{random.randint(1, 500):04d}',\n",
    "            'timestamp': (datetime.now() - timedelta(minutes=random.randint(0, 1440))).isoformat(),\n",
    "            'session_id': f'sess_{random.randint(1, 100):04d}',\n",
    "            'value': round(random.uniform(10, 500), 2)\n",
    "        }\n",
    "        events.append(event)\n",
    "    \n",
    "    return events\n",
    "\n",
    "# Generate and display sample events\n",
    "sample_events = generate_sample_events(5)\n",
    "print(\"Sample events:\")\n",
    "for event in sample_events:\n",
    "    print(json.dumps(event, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4df2cc",
   "metadata": {},
   "source": [
    "## Send Events to Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f233d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send events to Kafka\n",
    "def send_events_to_kafka(events, topic='raw-events'):\n",
    "    producer = KafkaProducer(\n",
    "        bootstrap_servers=['localhost:9092'],\n",
    "        value_serializer=lambda x: json.dumps(x).encode('utf-8')\n",
    "    )\n",
    "    \n",
    "    for event in events:\n",
    "        producer.send(topic, value=event)\n",
    "        print(f\"Sent: {event['event_type']} - {event['event_id']}\")\n",
    "    \n",
    "    producer.flush()\n",
    "    producer.close()\n",
    "    print(f\"\\nâœ… Sent {len(events)} events to topic '{topic}'\")\n",
    "\n",
    "# Send sample events\n",
    "send_events_to_kafka(sample_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f163bb",
   "metadata": {},
   "source": [
    "## Monitor Kafka Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c163571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor Kafka topic\n",
    "def monitor_kafka_topic(topic='raw-events', timeout=10):\n",
    "    consumer = KafkaConsumer(\n",
    "        topic,\n",
    "        bootstrap_servers=['localhost:9092'],\n",
    "        auto_offset_reset='latest',\n",
    "        enable_auto_commit=True,\n",
    "        group_id='jupyter-monitor',\n",
    "        value_deserializer=lambda m: json.loads(m.decode('utf-8'))\n",
    "    )\n",
    "    \n",
    "    print(f\"Monitoring topic '{topic}' for {timeout} seconds...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    message_count = 0\n",
    "    \n",
    "    for message in consumer:\n",
    "        message_count += 1\n",
    "        print(f\"Received: {message.value}\")\n",
    "        \n",
    "        if time.time() - start_time > timeout:\n",
    "            break\n",
    "    \n",
    "    consumer.close()\n",
    "    print(f\"\\nðŸ“Š Received {message_count} messages in {timeout} seconds\")\n",
    "\n",
    "# Uncomment to monitor (will block for 10 seconds)\n",
    "# monitor_kafka_topic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6682e225",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Check Kafka UI**: Open http://localhost:8080 to see topics and messages\n",
    "2. **Check Dagster**: Open http://localhost:3000 to see orchestration pipeline\n",
    "3. **Check Grafana**: Open http://localhost:3001 to see monitoring dashboards\n",
    "4. **Run data generator**: Execute the data generation script to create continuous stream\n",
    "5. **Test Spark jobs**: Run streaming jobs to process the data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
